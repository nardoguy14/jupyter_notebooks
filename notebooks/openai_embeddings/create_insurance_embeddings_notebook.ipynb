{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Using ChatGPT with New Data Part 1\n",
    "\n",
    "## About\n",
    "\n",
    "This is part 1 in utilizing ChatGPT APIs and Embeddings APIs to determine answers with ChatGPT on data not available to its model as of yet. Instead of fine tuning the model we use the embeddings for a different approach. \n",
    "\n",
    "1. Generate embeddings on owned data with OpenAI embeddings API\n",
    "2. Store embedding vectors for data somewhere, either in a csv or a vector database, this example uses a CSV to store the embeddings.\n",
    "3. Given a question we wish to ask ChatGPT, generate an embedding for the given question\n",
    "4. Find similarity of question vector to set of vectors from data to embedding vectors, this will tell us what info to provide to ChatGPT to figure out an answer to provide back\n",
    "5. Get the set of vectors from the stored embeddings to the amount of allowed tokens permissable as an api call to ChatGPT. Here we seek to give ChatGPT APIs the most data it can use to give a valid answer. We take the top N values such that when tokenized, it falls within the range allowed by ChatGPT\n",
    "6. Given the data and question, provide it to ChatGPT and get back an answer.\n",
    "\n",
    "This jupyter notebook here only focuses on creating the embeddings for the data we wish to use to answer questions. The example uses info scraped from https://www.healthforcalifornia.com/ to provide a way to find answers to questions about health insurance in California."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bba01fe25b3ead25"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from openai import OpenAI # for calling the OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import tiktoken  # for counting tokens\n",
    "import os # for getting API token from env variable OPENAI_API_KEY\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "\n",
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "OPEN_AI_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPEN_AI_KEY)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:30:27.040240Z",
     "start_time": "2024-04-26T07:30:27.025622Z"
    }
   },
   "id": "28fba910caf070f4",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_query_embeddings(query: str) -> list[float]:\n",
    "    \"\"\"\n",
    "    Function to call OpenAI embeddings API and return back a vector representing the embedding.\n",
    "    \n",
    "    :param query: The text we want to derive an embedding from\n",
    "    :return: list[float] representing the embedding\n",
    "    \"\"\"\n",
    "    query_embedding_response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    return query_embedding\n",
    "\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"\n",
    "        Return the number of tokens in a string.\n",
    "        This helps when knowing ho wmuch data we can pass to ChatGPT APIs since there are\n",
    "        limits on the maount of tokens that can be provided to ChatGPT.\n",
    "        \n",
    "        :param text: The text we want to calculate number of tokens for\n",
    "        :param model: Model we will cal from which we want to calculate tokens for\n",
    "        :return: int Number representing amount of tokens given text and model\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:30:27.040888Z",
     "start_time": "2024-04-26T07:30:27.036361Z"
    }
   },
   "id": "3f30f84583399955",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "files = ['aetna.txt',\n",
    "         'anthem_blue_cross.txt',\n",
    "         'blue_shield.txt',\n",
    "         'bronze_option.txt',\n",
    "         'cchp.txt',\n",
    "         'deadlines.txt',\n",
    "         'family_options.txt',\n",
    "         'gold_option.txt',\n",
    "         'government_discounts.txt',\n",
    "         'health_net.txt',\n",
    "         'hmo_vs_ppo.txt',\n",
    "         'iehp.txt',\n",
    "         'income_limits.txt',\n",
    "         'individual_options.txt',\n",
    "         'irs_1095_a_form.txt',\n",
    "         'kaiser.txt',\n",
    "         'la_care_health_plan.txt',\n",
    "         'medi_cal_options.txt',\n",
    "         'minimum_option.txt',\n",
    "         'molina_health',\n",
    "         'newborn_options.txt',\n",
    "         'open_enrollment.txt',\n",
    "         'platinum_option.txt',\n",
    "         'preventative_care.txt',\n",
    "         'qualifying_life_events.txt',\n",
    "         'reporting_changes.txt',\n",
    "         'self_employed_options.txt',\n",
    "         'senior_options.txt',\n",
    "         'sharp.txt',\n",
    "         'should_switch_to_hmo.txt',\n",
    "         'silver_70_option.txt',\n",
    "         'silver_73_option.txt',\n",
    "         'silver_87_option.txt',\n",
    "         'silver_94_option.txt',\n",
    "         'silver_option.txt',\n",
    "         'small_business_options.txt',\n",
    "         'special_enrollment.txt',\n",
    "         'supplemental_options.txt',\n",
    "         'travel_options.txt',\n",
    "         'valley_health_plan.txt',\n",
    "         'western_health_plan.txt'\n",
    "         ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:30:27.048108Z",
     "start_time": "2024-04-26T07:30:27.041896Z"
    }
   },
   "id": "ac042192c1df0b9e",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_contents = []\n",
    "for file in files:\n",
    "    with open(f\"../../datasets/covered_california_2024/{file}\", 'r') as file:\n",
    "        content = file.read()\n",
    "        file_contents.append(content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:30:27.054911Z",
     "start_time": "2024-04-26T07:30:27.048564Z"
    }
   },
   "id": "1be608f73ad5c43a",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "37348"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = 0\n",
    "for content in file_contents:\n",
    "    tokens += num_tokens(content, EMBEDDING_MODEL)\n",
    "tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:30:27.076452Z",
     "start_time": "2024-04-26T07:30:27.055647Z"
    }
   },
   "id": "b7eeb595f7cc3e81",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for content in file_contents:\n",
    "    # embeddings.append(get_query_embeddings(content))\n",
    "    continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:30:27.080574Z",
     "start_time": "2024-04-26T07:30:27.077008Z"
    }
   },
   "id": "4b62a8b54b4c259b",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = {\n",
    "    'text': file_contents,\n",
    "    'embeddings': embeddings\n",
    "}\n",
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv('data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:30:27.082889Z",
     "start_time": "2024-04-26T07:30:27.079449Z"
    }
   },
   "id": "8479ac45a312fb94",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T07:30:27.085322Z",
     "start_time": "2024-04-26T07:30:27.082590Z"
    }
   },
   "id": "58d14eac1396d251",
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
